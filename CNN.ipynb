{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45845f7a",
   "metadata": {},
   "source": [
    "Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3951f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a51382d",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283fd0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Dataset Loading (EXACTLY same as your original)\n",
    "def load_dataset(txt_file):\n",
    "    data, labels = [], []\n",
    "    with open(txt_file, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            image_path = line.strip()\n",
    "            if os.path.exists(image_path):\n",
    "                label = image_path.split('/')[1] \n",
    "                data.append(image_path)\n",
    "                labels.append(label)\n",
    "    return pd.DataFrame({'image_path': data, 'label': labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea605f3",
   "metadata": {},
   "source": [
    "Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ec9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Simple CNN Model (minimal implementation)\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(32*16*16, num_classes)  # Adjusted for 64x64 input\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bae72d",
   "metadata": {},
   "source": [
    "Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b494e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Image Preprocessing (matches your resize to 64x64)\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = image.transpose(2, 0, 1)  # HWC to CHW\n",
    "    return torch.FloatTensor(image) / 255.0  # Normalize to [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836a614",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0a79d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results [LR=0.0001, BS=32, Epochs=20]:\n",
      "Test Accuracy: 0.9100\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor       0.95      0.87      0.91       100\n",
      "museum-outdoor       0.88      0.95      0.91       100\n",
      "\n",
      "      accuracy                           0.91       200\n",
      "     macro avg       0.91      0.91      0.91       200\n",
      "  weighted avg       0.91      0.91      0.91       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Main Workflow (matches your original structure)\n",
    "\n",
    "lr = 0.0001  # Learning rate (same as original)\n",
    "epochs = 20  # Number of epochs (same as original)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load datasets (same as original)\n",
    "    train_df = load_dataset(\"train.txt\")\n",
    "    test_df = load_dataset(\"val.txt\")  # Using val.txt as test per your original\n",
    "    \n",
    "    # Prepare data (simplified version of your workflow)\n",
    "    X_train = torch.stack([preprocess_image(path) for path in train_df['image_path']])\n",
    "    X_test = torch.stack([preprocess_image(path) for path in test_df['image_path']])\n",
    "    \n",
    "    # Encode labels (same as original)\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(train_df['label'])\n",
    "    y_test = encoder.transform(test_df['label'])\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_test = torch.LongTensor(y_test)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = SimpleCNN(num_classes=len(encoder.classes_))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop (basic version)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluation (matches your original metrics)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        _, predicted = torch.max(test_outputs, 1)\n",
    "        accuracy = (predicted == y_test).float().mean()\n",
    "        \n",
    "    print(f\"\\nResults [LR={lr}, BS={32}, Epochs={epochs}]:\")\n",
    "    print(f\"Test Accuracy: {accuracy.item():.4f}\")\n",
    "\n",
    "\n",
    "    # Generate classification report (added)\n",
    "    y_true = y_test.numpy()\n",
    "    y_pred = predicted.numpy()\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=encoder.classes_))\n",
    "    \n",
    "    # Save predictions (same format as original)\n",
    "    test_df['Predicted Label'] = encoder.inverse_transform(predicted.numpy())\n",
    "    test_df.to_csv(\"test_predictions_cnn.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

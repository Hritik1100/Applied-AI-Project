{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "898bf8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82ae5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 1. Generate unlabeled.txt from train.txt ----\n",
    "def generate_unlabeled_file(train_txt, unlabeled_txt):\n",
    "    \"\"\"\n",
    "    Generates an 'unlabeled.txt' file by copying the paths from 'train.txt'.\n",
    "    \n",
    "    Arguments:\n",
    "        train_txt (str): The path to the labeled training dataset text file.\n",
    "        unlabeled_txt (str): The path where the unlabeled dataset text file will be saved.\n",
    "    \"\"\"\n",
    "    with open(train_txt, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Save the same paths to unlabeled.txt\n",
    "    with open(unlabeled_txt, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "        \n",
    "    print(f\"Unlabeled dataset saved to {unlabeled_txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8232a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 2. Load Dataset ----\n",
    "def load_dataset(txt_file):\n",
    "    data, labels = [], []\n",
    "    \n",
    "    with open(txt_file, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            image_path = line.strip()\n",
    "            full_path = os.path.join(image_path)\n",
    "            if os.path.exists(full_path):\n",
    "                label = image_path.split('/')[1]  # Extracting label from path\n",
    "                data.append(full_path)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return pd.DataFrame({'image_path': data, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60536a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 3. Feature Extraction ----\n",
    "def extract_features(image_path):\n",
    "    \"\"\"\n",
    "    Extracts color histograms from an image and returns a feature vector.\n",
    "    Arguments:\n",
    "        image_path (str): Path to the image file.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (64, 64))  # Resize for uniformity\n",
    "    \n",
    "    # Compute histograms for each color channel (Blue, Green, Red)\n",
    "    hist_b = cv2.calcHist([image], [0], None, [256], [0, 256])\n",
    "    hist_g = cv2.calcHist([image], [1], None, [256], [0, 256])\n",
    "    hist_r = cv2.calcHist([image], [2], None, [256], [0, 256])\n",
    "\n",
    "    # Normalize histograms\n",
    "    hist_b = cv2.normalize(hist_b, hist_b).flatten()\n",
    "    hist_g = cv2.normalize(hist_g, hist_g).flatten()\n",
    "    hist_r = cv2.normalize(hist_r, hist_r).flatten()\n",
    "\n",
    "    # Concatenate histograms into a single feature vector\n",
    "    feature_vector = np.concatenate([hist_b, hist_g, hist_r])\n",
    "\n",
    "    return feature_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54509947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 4. Main Process ----\n",
    "# Paths to your datasets\n",
    "train_txt = 'train.txt'  # Path to the labeled training file\n",
    "unlabeled_txt = 'unlabeled.txt'  # Path to save the new unlabeled dataset file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "205766a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlabeled dataset saved to unlabeled.txt\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Generate unlabeled.txt from train.txt\n",
    "generate_unlabeled_file(train_txt, unlabeled_txt)\n",
    "\n",
    "# Step 2: Load Labeled and Unlabeled Datasets\n",
    "labeled_dataset = load_dataset(train_txt)  # Labeled data\n",
    "unlabeled_dataset = load_dataset(unlabeled_txt)  # Unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Feature Extraction (Labeled Data)\n",
    "features_labeled = np.array([extract_features(path) for path in labeled_dataset['image_path']])\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(labeled_dataset['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f69117ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction for Unlabeled Data (No Labels)\n",
    "features_unlabeled = np.array([extract_features(path) for path in unlabeled_dataset['image_path']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15182807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled Data Shape: (10000, 768)\n",
      "Unlabeled Data Shape: (10000, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Labeled Data Shape:\", features_labeled.shape)\n",
    "print(\"Unlabeled Data Shape:\", features_unlabeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e094817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised Decision Tree Model saved.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the Random Forest Model (Labeled Data)\n",
    "rf_model = DecisionTreeClassifier(random_state=42)\n",
    "rf_model.fit(features_labeled, y_encoded)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(rf_model, \"unsupervised_DT_model.pkl\")\n",
    "joblib.dump(encoder, \"label_encoder.pkl\")  # Save the label encoder for inverse transformation\n",
    "print(\"Unsupervised Decision Tree Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c269cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Pseudo-labeling (Semi-Supervised Learning)\n",
    "# Use the trained model to predict on the unlabeled data\n",
    "pseudo_labels = rf_model.predict(features_unlabeled)\n",
    "\n",
    "# Assign pseudo-labels to the unlabeled dataset\n",
    "unlabeled_dataset['Predicted Label'] = encoder.inverse_transform(pseudo_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48513dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine labeled and pseudo-labeled data\n",
    "combined_features = np.vstack([features_labeled, features_unlabeled])\n",
    "combined_labels = np.hstack([y_encoded, pseudo_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "957a6096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semi-Supervised model re-trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Re-train the model with combined dataset (Semi-Supervised)\n",
    "rf_model.fit(combined_features, combined_labels)\n",
    "joblib.dump(rf_model, \"semi_supervised_model.pkl\")  # Save the new model\n",
    "print(\"Semi-Supervised model re-trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26116424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- 7. Evaluate Model on Test Data ----\n",
    "# Load Test Dataset\n",
    "test_txt = \"val.txt\"  # Test dataset file\n",
    "test_dataset = load_dataset(test_txt)\n",
    "\n",
    "# Extract features for the test dataset\n",
    "test_features = np.array([extract_features(path) for path in test_dataset['image_path']])\n",
    "\n",
    "# Predict on Test Data\n",
    "test_predictions = rf_model.predict(test_features)\n",
    "predicted_labels = encoder.inverse_transform(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0defcac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Save Predictions\n",
    "test_dataset['Predicted Label'] = predicted_labels\n",
    "test_dataset.to_csv(\"test_predictions.csv\", index=False)\n",
    "print(\"Predictions saved to test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26ec8401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7450\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      " museum-indoor     0.7579    0.7200    0.7385       100\n",
      "museum-outdoor     0.7333    0.7700    0.7512       100\n",
      "\n",
      "      accuracy                         0.7450       200\n",
      "     macro avg     0.7456    0.7450    0.7448       200\n",
      "  weighted avg     0.7456    0.7450    0.7448       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy and classification metrics\n",
    "y_true = encoder.transform(test_dataset['label'])\n",
    "accuracy = accuracy_score(y_true, test_predictions)\n",
    "report = classification_report(y_true, test_predictions, target_names=encoder.classes_, digits=4)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

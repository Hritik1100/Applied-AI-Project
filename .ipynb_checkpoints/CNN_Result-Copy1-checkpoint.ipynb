{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb5ebf0-c6cf-433d-aa5f-42d802b7ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, TensorDataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc = nn.Linear(32*16*16, num_classes)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b20f3f8f-2151-4d1d-a57f-edcee6293aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(txt_file):\n",
    "    data, labels = [], []\n",
    "    with open(txt_file, 'r') as file:\n",
    "        for line in file.readlines():\n",
    "            image_path = line.strip()\n",
    "            if os.path.exists(image_path):\n",
    "                label = image_path.split('/')[1] \n",
    "                data.append(image_path)\n",
    "                labels.append(label)\n",
    "    return pd.DataFrame({'image_path': data, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9df5f73-187d-40ad-a5d4-280127506531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = image.transpose(2, 0, 1) \n",
    "    return torch.FloatTensor(image) / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c24be21d-765d-4386-8336-e1549b98f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_CNN(lr, epochs, train_loader, val_loader, save_model=False):\n",
    "    model = SimpleCNN(num_classes=len(encoder.classes_))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = []\n",
    "        val_labels = []\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            val_outputs.append(outputs)\n",
    "            val_labels.append(labels)\n",
    "        \n",
    "        val_outputs = torch.cat(val_outputs)\n",
    "        val_labels = torch.cat(val_labels)\n",
    "        _, predicted = torch.max(val_outputs, 1)\n",
    "        val_accuracy = (predicted == val_labels).float().mean()\n",
    "    \n",
    "    if save_model:\n",
    "        model_name = f\"cnn_lr{lr}_epochs{epochs}.pth\"\n",
    "        torch.save(model.state_dict(), f\"saved_models/{model_name}\")\n",
    "    \n",
    "    return val_accuracy.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51e07f93-d147-43a0-b90c-81055161d0a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TensorDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train))\n\u001b[0;32m     10\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X_train) \u001b[38;5;241m-\u001b[39m train_size\n\u001b[0;32m     11\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m random_split(\n\u001b[1;32m---> 12\u001b[0m     TensorDataset(X_train, y_train), \n\u001b[0;32m     13\u001b[0m     [train_size, val_size]\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     16\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TensorDataset' is not defined"
     ]
    }
   ],
   "source": [
    "os.makedirs('saved_models', exist_ok=True)\n",
    "train_df = load_dataset(\"train.txt\")\n",
    "\n",
    "X_train = torch.stack([preprocess_image(path) for path in train_df['image_path']])\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(train_df['label'])\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "train_size = int(0.8 * len(X_train))\n",
    "val_size = len(X_train) - train_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    TensorDataset(X_train, y_train), \n",
    "    [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "configurations = [\n",
    "    (0.01, 10),\n",
    "    (0.01, 20),\n",
    "    (0.001, 10),\n",
    "    (0.001, 20),\n",
    "    (0.0001, 10),\n",
    "    (0.0001, 20)\n",
    "]\n",
    "\n",
    "results = {}\n",
    "print(\"Running all configurations...\")\n",
    "for lr, epochs in configurations:\n",
    "    print(f\"\\nRunning configuration: LR={lr}, Epochs={epochs}\")\n",
    "    val_acc = run_CNN(lr, epochs, train_loader, val_loader, save_model=True)\n",
    "    results[(lr, epochs)] = val_acc\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "best_config = max(results.items(), key=lambda x: x[1])\n",
    "best_lr, best_epochs = best_config[0]\n",
    "print(f\"\\nBest configuration: LR={best_lr}, Epochs={best_epochs} with Val Accuracy={best_config[1]:.4f}\")\n",
    "\n",
    "print(\"\\nGenerating detailed report for best model on validation set...\")\n",
    "best_model = SimpleCNN(num_classes=len(encoder.classes_))\n",
    "best_model.load_state_dict(torch.load(f\"saved_models/cnn_lr{best_lr}_epochs{best_epochs}.pth\"))\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = []\n",
    "    val_labels = []\n",
    "    for images, labels in val_loader:\n",
    "        outputs = best_model(images)\n",
    "        val_outputs.append(outputs)\n",
    "        val_labels.append(labels)\n",
    "    \n",
    "    val_outputs = torch.cat(val_outputs)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "    _, predicted = torch.max(val_outputs, 1)\n",
    "    \n",
    "    y_true = val_labels.numpy()\n",
    "    y_pred = predicted.numpy()\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=encoder.classes_))\n",
    "    \n",
    "    val_df = train_df.iloc[val_dataset.indices].copy()\n",
    "    val_df['Predicted Label'] = encoder.inverse_transform(predicted.numpy())\n",
    "    val_df.to_csv(\"best_model_val_predictions.csv\", index=False)\n",
    "    print(\"\\nSaved validation predictions to 'best_model_val_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f253fc7-b532-4bec-b643-cfeb979eb65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_evaluate_best_model(best_lr, best_epochs):\n",
    "    val_df = load_dataset(\"val.txt\")\n",
    "\n",
    "    X_val = torch.stack([preprocess_image(path) for path in val_df['image_path']])\n",
    "    y_val = encoder.transform(val_df['label'])\n",
    "    y_val = torch.LongTensor(y_val)\n",
    "\n",
    "    val_dataset = TensorDataset(X_val, y_val)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "    best_model = SimpleCNN(num_classes=len(encoder.classes_))\n",
    "    model_path = f\"saved_models/cnn_lr{best_lr}_epochs{best_epochs}.pth\"\n",
    "    best_model.load_state_dict(torch.load(model_path))\n",
    "    best_model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = best_model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=encoder.classes_))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=encoder.classes_, \n",
    "                yticklabels=encoder.classes_)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "    val_df['Predicted Label'] = encoder.inverse_transform(y_pred)\n",
    "    val_df.to_csv(\"final_val_predictions.csv\", index=False)\n",
    "    print(\"\\nSaved predictions to 'final_val_predictions.csv'\")\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_lr = 0.0001  \n",
    "best_epochs = 20  \n",
    "\n",
    "\n",
    "y_true, y_pred = load_and_evaluate_best_model(best_lr, best_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "81c0d15c-4937-4ece-8b74-4c8aa61145d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Indoor/Outdoor Image Classifier\n",
      "-----------------------------\n",
      "Note: Please ensure the image path is correct and the image is in common format (jpg, png, etc.)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter image path:  train//museum-outdoor//00000041.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: This image looks like outdoor!\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('saved_models/cnn_lr0.0001_epochs20.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = image.transpose(2, 0, 1) \n",
    "    return torch.FloatTensor(image) / 255.0  \n",
    "\n",
    "def predict(image_path, model):\n",
    "    input_tensor = preprocess_image(image_path).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return \"outdoor\" if predicted.item() == 1 else \"indoor\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = SimpleCNN(num_classes=2)\n",
    "    model.load_state_dict(torch.load('saved_models/cnn_lr0.001_epochs20.pth', map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"\\nIndoor/Outdoor Image Classifier\")\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Note: Please ensure the image path is correct and the image is in common format (jpg, png, etc.)\")\n",
    "    \n",
    "    image_path = input(\"\\nEnter image path: \").strip()\n",
    "            \n",
    "    try:\n",
    "        prediction = predict(image_path, model)\n",
    "        print(f\"Prediction: This image looks like {prediction}!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca64ae4-e938-4043-81e0-dc6152140e35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
